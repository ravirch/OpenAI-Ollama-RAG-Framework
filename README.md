### **RAG Framework with OpenAI and Open-Source Models using Ollama**

This project demonstrates the implementation of a Retrieval-Augmented Generation (RAG) framework using OpenAI and Ollama. It covers data ingestion, transformation, vector databases, and retrieval workflows. The project also integrates open-source models via Ollama with a Streamlit interface but focuses on RAG implementation in Jupyter notebooks using OpenAI models.

---

### **Project Overview**

The project is divided into the following stages:

1. **Data Ingestion**:
   - Implemented various techniques like text loaders and PDF loaders to ingest data for processing.
   - Built pipelines to prepare diverse datasets for downstream tasks.

2. **Data Transformation**:
   - Used recursive split, character split, and text split techniques to break down large datasets into manageable chunks.
   - Optimized the data for embedding generation and retrieval.

3. **Embeddings**:
   - Generated embeddings using OpenAI models for RAG in Jupyter notebooks.
   - Integrated OllamaEmbedding for experimenting with open-source models.

4. **Vector Store**:
   - Utilized FAISS and Chroma to create and manage vector databases for fast and efficient retrieval operations.

5. **RAG Framework (in Jupyter Notebooks)**:
   - Demonstrated RAG using OpenAI LLMs for intelligent query resolution.
   - Built retrieval chains to fetch relevant data and provide contextual responses.

6. **Open-Source Model Integration (with Streamlit)**:
   - Developed a Streamlit app using Ollama to explore the capabilities of open-source language models.
   - Focused on querying and interacting with open-source models through a simple interface.

---

### **Contributions**

Contributions are welcome! Feel free to open issues or submit pull requests to expand and improve the project.

---

### **Acknowledgments**

This project was inspired by Krish Naik's course on Generative AI. Special thanks to Krish Naik for his insights and guidance.
