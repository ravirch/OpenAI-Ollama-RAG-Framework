{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "\n",
    "# this is for langsmith tracking\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x0000019A835C2CF0> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000019A835C0200> root_client=<openai.OpenAI object at 0x0000019A81C3DC70> root_async_client=<openai.AsyncOpenAI object at 0x0000019A835C2DB0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a category of artificial intelligence systems designed to create new content. These systems use advanced algorithms, often based on neural networks, to generate text, images, music, and other types of data. The underlying technology frequently involves models like Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformer-based models such as GPT (Generative Pre-trained Transformer).\\n\\nGenerative AI models learn patterns from existing data and use this knowledge to produce novel outputs that are similar in style or content. For instance, a generative AI trained on a large corpus of text can produce human-like text, while one trained on images can create new images that resemble the training data.\\n\\nApplications of generative AI are diverse and include creative industries (e.g., art and music creation), content generation (e.g., writing assistance and automated storytelling), design (e.g., fashion and architecture), and more. While these technologies offer exciting possibilities, they also raise ethical considerations, such as the potential for misuse in generating misleading information or deepfakes.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 216, 'prompt_tokens': 13, 'total_tokens': 229, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_5f20662549', 'finish_reason': 'stop', 'logprobs': None} id='run-da7252a8-22f2-4a42-8f21-7f687da0cfde-0' usage_metadata={'input_tokens': 13, 'output_tokens': 216, 'total_tokens': 229, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generative AI refers to a category of artificial intelligence systems designed to create new content. These systems use advanced algorithms, often based on neural networks, to generate text, images, music, and other types of data. The underlying technology frequently involves models like Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformer-based models such as GPT (Generative Pre-trained Transformer).\\n\\nGenerative AI models learn patterns from existing data and use this knowledge to produce novel outputs that are similar in style or content. For instance, a generative AI trained on a large corpus of text can produce human-like text, while one trained on images can create new images that resemble the training data.\\n\\nApplications of generative AI are diverse and include creative industries (e.g., art and music creation), content generation (e.g., writing assistance and automated storytelling), design (e.g., fashion and architecture), and more. While these technologies offer exciting possibilities, they also raise ethical considerations, such as the potential for misuse in generating misleading information or deepfakes.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a tool developed by Langchain to enhance the development and deployment of language model applications. It provides a robust platform for testing, tracing, and evaluating these applications. Langsmith is designed to help developers understand how their language models perform, identify areas for improvement, and ensure reliability and efficiency in their applications. Key features include the ability to track the performance of language models in real-time, analyze interaction traces to diagnose issues, and conduct comprehensive evaluations to optimize application behavior. This makes it a valuable resource for developers working with language models, allowing for continuous improvement and fine-tuning of their applications.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 121, 'prompt_tokens': 33, 'total_tokens': 154, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_5f20662549', 'finish_reason': 'stop', 'logprobs': None} id='run-35b76276-09dd-4101-b6ba-d345c81461c9-0' usage_metadata={'input_tokens': 33, 'output_tokens': 121, 'total_tokens': 154, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a comprehensive toolset developed by LangChain, designed to assist developers in building, monitoring, and evaluating applications that leverage large language models (LLMs). It addresses common challenges faced when developing LLM-powered applications by providing a suite of tools that enhance the development process.\n",
      "\n",
      "Key features of Langsmith include:\n",
      "\n",
      "1. **Testing and Evaluation**: Langsmith offers capabilities to test and evaluate the performance of language models. This includes tools for debugging and fine-tuning models to ensure they function as expected in various scenarios.\n",
      "\n",
      "2. **Monitoring**: It provides monitoring tools that allow developers to track the usage and performance of their applications in real-time. This helps in identifying issues, understanding user interactions, and optimizing the application's performance.\n",
      "\n",
      "3. **Seamless Integration**: Langsmith integrates smoothly with the LangChain framework, enabling developers to create complex applications with enhanced functionalities such as chaining multiple models or combining them with other computational processes.\n",
      "\n",
      "4. **User-Friendly Interface**: Designed to be accessible, Langsmith offers a user-friendly interface that simplifies the process of managing and iterating on language model-driven applications.\n",
      "\n",
      "Langsmith is part of the broader LangChain ecosystem, which focuses on simplifying the development of applications that utilize language models by providing robust infrastructure and tools.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser: string output parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
